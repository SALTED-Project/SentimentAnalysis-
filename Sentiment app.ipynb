{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lID7Vfn4zkyM"
      },
      "outputs": [],
      "source": [
        "# For translation\n",
        "!pip install -U deep-translator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For sentiment analysis\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install sacremoses"
      ],
      "metadata": {
        "id": "QNhiPU7yz5Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import json\n",
        "from dateutil import parser"
      ],
      "metadata": {
        "id": "QB51Gg_oz9PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some Parameters to Be Initiated Before Running the Code"
      ],
      "metadata": {
        "id": "Mmdo9BWS20-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to track users set this to 1, if you want to track by hashtags set to 0\n",
        "TrackUsers = 0\n",
        "# If you want to do sentiment analysis set this to 1\n",
        "SentimentAnalysis = 1\n",
        "# If you want to create a new collection entity, set this to 0 and add the collection description\n",
        "CreateCollection = 1\n",
        "CollectionDescription = 'This is a collection of tweets and sentiments about the traffic in Madrid'\n",
        "# If you want the recovered tweets to belong to a collection, set this to 1\n",
        "BelongsToCollection = 1"
      ],
      "metadata": {
        "id": "XbCGiDsE266P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crawling Tweets"
      ],
      "metadata": {
        "id": "J5ubShKM0C0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"\"\n",
        "api_key_secret= \"\"\n",
        "access_token = \"\"\n",
        "access_token_secret = \"\"\n",
        "\n",
        "# authentication\n",
        "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth)"
      ],
      "metadata": {
        "id": "Bf4VLJgi0GpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hashtags or keywords to search for\n",
        "hashtags = [\"#traffic\", \"#globalwarming\"]\n",
        "\n",
        "# Define the users to search for\n",
        "users = [\"@LeoDiCaprio\"]"
      ],
      "metadata": {
        "id": "rhnwREUl0KuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of objects you want returned\n",
        "limit_hashtagtweets = 1\n",
        "limit_usertimeline = 1\n",
        "tweets = []"
      ],
      "metadata": {
        "id": "eISwYbnC0rTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Historical tweet crawling based on keywords (or hashtags)\n",
        "if not TrackKeywords:\n",
        "  for hashtag in hashtags:\n",
        "      tweets_hashtag = tweepy.Cursor(api.search_tweets,\n",
        "                                    q=hashtag,\n",
        "                                    tweet_mode='extended').items(limit_hashtagtweets)\n",
        "      for tweet in tweets_hashtag:\n",
        "          tweets.append(tweet)"
      ],
      "metadata": {
        "id": "a1_zIzYw0rlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect historical tweets posted by the users\n",
        "if TrackUsers:\n",
        "  for user in users:\n",
        "      tweets_user = tweepy.Cursor(api.user_timeline,\n",
        "                                  screen_name=user,\n",
        "                                  # since_id=start_date,\n",
        "                                  # until=end_date,\n",
        "                                  tweet_mode='extended').items(limit_usertimeline)\n",
        "      for tweet in tweets_user:\n",
        "          tweets.append(tweet)"
      ],
      "metadata": {
        "id": "iuTodyrY0u3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Function to Hash the Input and Create IDs"
      ],
      "metadata": {
        "id": "4aii-zQy2QfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "def HashSentence(sentence):\n",
        "    # Convert the sentence to bytes since hashlib works with bytes\n",
        "    sentence_bytes = sentence.encode('utf-8')\n",
        "\n",
        "    # Create a SHA-256 hash object\n",
        "    sha256_hash = hashlib.sha256()\n",
        "\n",
        "    # Update the hash object with the sentence bytes\n",
        "    sha256_hash.update(sentence_bytes)\n",
        "\n",
        "    # Get the hexadecimal representation of the hash\n",
        "    hashed_id = sha256_hash.hexdigest()\n",
        "\n",
        "    return str(hashed_id)\n",
        "\n",
        "def HashID(id2hash):\n",
        "    # Convert the id to bytes since hashlib works with bytes\n",
        "    id_bytes = str(id2hash).encode('utf-8')\n",
        "\n",
        "    # Create a SHA-256 hash object\n",
        "    sha256_hash = hashlib.sha256()\n",
        "\n",
        "    # Update the hash object with the id bytes\n",
        "    sha256_hash.update(id_bytes)\n",
        "\n",
        "    # Get the hexadecimal representation of the hash\n",
        "    hashed_id = sha256_hash.hexdigest()\n",
        "\n",
        "    return str(hashed_id)"
      ],
      "metadata": {
        "id": "wlT4G4Za2awv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NGSI-LD Tweet, User, and Collection Entity Creation Functions"
      ],
      "metadata": {
        "id": "EQbVQmUD1LrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MapTweet2NGSILD (tweet, generated_user_id = 'NA', generated_post_id = 'NA', generated_collection_id = 'NA', generated_dataset_id = '0'):\n",
        "    if generated_post_id == 'NA':\n",
        "      generated_post_id = HashID(tweet['id'])\n",
        "    if generated_user_id == 'NA':\n",
        "      generated_user_id = HashID(tweet['user']['id'])\n",
        "    tweet_entity = {\n",
        "        \"id\": \"urn:ngsi-ld:SMPost:\" + generated_post_id,\n",
        "        \"type\": \"SMPost\",\n",
        "        \"belongsToCollection\": [\n",
        "        ],\n",
        "\n",
        "        \"createdBy\": {\n",
        "            \"type\": \"Relationship\",\n",
        "            \"object\": \"urn:ngsi-ld:SMUser:\" + generated_user_id\n",
        "        },\n",
        "\n",
        "        \"hasAnalysis\": [\n",
        "        ],\n",
        "\n",
        "        \"platform\": {\n",
        "            \"type\": \"Property\",\n",
        "            \"value\": \"Twitter\"\n",
        "        },\n",
        "\n",
        "        \"postCreatedAt\": {\n",
        "            \"type\": \"Property\",\n",
        "            \"value\": {\n",
        "                \"@type\": \"DateTime\",\n",
        "                \"@value\": parser.parse(tweet['created_at']).isoformat()\n",
        "            }\n",
        "        },\n",
        "\n",
        "        \"postId\": {\n",
        "            \"type\": \"Property\",\n",
        "            \"value\": tweet['id_str']\n",
        "        },\n",
        "\n",
        "        \"@context\": [\n",
        "            \"https://raw.githubusercontent.com/smart-data-models/dataModel.SocialMedia/master/context.jsonld\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Check if generated_collection_id is not 'NA' before adding to \"belongsToCollection\"\n",
        "    if generated_collection_id != 'NA':\n",
        "        tweet_entity[\"belongsToCollection\"].append({\n",
        "            \"type\": \"Relationship\",\n",
        "            \"object\": \"urn:ngsi-ld:SMCollection:\" + generated_collection_id,\n",
        "            \"datasetId\": \"urn:ngsi-ld:Dataset:SMCollection:\" + generated_dataset_id\n",
        "        })\n",
        "\n",
        "    return tweet_entity"
      ],
      "metadata": {
        "id": "3Vw0Hh-p2gMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CreateUserEntity(tweet, generated_user_id = 'NA', generated_post_id = 'NA', generated_dataset_id = '0'):\n",
        "    user = tweet['user']\n",
        "    if generated_user_id == 'NA':\n",
        "      generated_user_id = HashID(user['id'])\n",
        "    if generated_post_id == 'NA':\n",
        "      generated_post_id = HashID(tweet['id'])\n",
        "\n",
        "    user_entity = {\n",
        "        \"id\": \"urn:ngsi-ld:SMUser:\" + generated_user_id,\n",
        "        \"type\": \"SMUser\",\n",
        "\n",
        "        \"createdPosts\": [\n",
        "            {\n",
        "                \"type\": \"Relationship\",\n",
        "                \"object\": \"urn:ngsi-ld:SMPost:\" + generated_post_id,\n",
        "                \"datasetId\": \"urn:ngsi-ld:Dataset:SMPost:\" + generated_post_id\n",
        "            }\n",
        "        ],\n",
        "\n",
        "        \"platform\": {\n",
        "            \"type\": \"Property\",\n",
        "            \"value\": \"Twitter\"\n",
        "        },\n",
        "\n",
        "        \"userId\": {\n",
        "            \"type\": \"Property\",\n",
        "            \"value\": user['id_str']\n",
        "        },\n",
        "\n",
        "        \"@context\": [\n",
        "            \"https://raw.githubusercontent.com/smart-data-models/dataModel.SocialMedia/master/context.jsonld\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return user_entity"
      ],
      "metadata": {
        "id": "zCUizgpI3hfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CreateCollectionEntity(generated_collection_id = 'NA', description = 'No Description Added'):\n",
        "\n",
        "    if generated_collection_id == 'NA':\n",
        "      generated_collection_id = HashSentence(description)\n",
        "\n",
        "    collection = {\n",
        "        \"id\": \"urn:ngsi-ld:SMCollection:\" + generated_collection_id,\n",
        "        \"type\": \"SMCollection\",\n",
        "        \"description\": {\n",
        "            \"type\": \"Property\",\n",
        "            \"value\": description\n",
        "        },\n",
        "        \"groupedAt\": {\n",
        "            \"type\": \"Property\",\n",
        "            \"value\": {\n",
        "                \"@type\": \"DateTime\",\n",
        "                \"@value\": datetime.now().isoformat()\n",
        "            }\n",
        "        },\n",
        "        \"hasAnalysis\": [\n",
        "        ],\n",
        "        \"hasPosts\": [\n",
        "        ],\n",
        "\n",
        "        \"@context\": [\n",
        "            \"https://raw.githubusercontent.com/smart-data-models/dataModel.SocialMedia/master/context.jsonld\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return collection"
      ],
      "metadata": {
        "id": "oRboOBtf34bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NGSI-LD Sentiment Analysis Entity Creation"
      ],
      "metadata": {
        "id": "3261RVyK347o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a translator funcion to first translate tweets and then apply sentiment analysis\n",
        "\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def GenerateTranslation (text_to_translate):\n",
        "  translated_text = GoogleTranslator(source='auto', target='en').translate(text_to_translate)\n",
        "  return translated_text"
      ],
      "metadata": {
        "id": "F7VfEASr4EhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a sentiment analysis pipeline\n",
        "\n",
        "from transformers import pipeline\n",
        "# specific_model = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
        "# specific_model(data)\n",
        "sentiment_analyzer = pipeline('sentiment-analysis')"
      ],
      "metadata": {
        "id": "PG5PchGS4Kvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def CreateSentimentAnalysisEntity(tweet, translated_text, PostId = 'NA', generated_analysis_id = 'NA'):\n",
        "\n",
        "    if PostId == 'NA':\n",
        "      PostId = 'urn:ngsi-ld:SMPost:' + HashID(tweet['id'])\n",
        "    if generated_analysis_id == 'NA':\n",
        "      generated_analysis_id = HashID(tweet['id'])\n",
        "\n",
        "    text_sentiment = sentiment_analyzer(translated_text)\n",
        "    analysis = {\n",
        "        \"id\": \"urn:ngsi-ld:Analysis:Sentiment:\" + generated_analysis_id,\n",
        "        \"type\": \"SMAnalysis\",\n",
        "        \"analyzedAt\": {\n",
        "            \"type\": \"Property\",\n",
        "            \"value\": {\n",
        "                \"@type\": \"DateTime\",\n",
        "                \"@value\": datetime.now().isoformat()\n",
        "            }\n",
        "        },\n",
        "        \"hasAnalysisType\": {\n",
        "            \"type\": \"Property\",\n",
        "            \"value\": \"Sentiment\"\n",
        "        },\n",
        "        \"hasAnalysisValue\": {\n",
        "            \"type\": \"Property\",\n",
        "            \"value\": text_sentiment[0]['label']\n",
        "        },\n",
        "        \"hasConfidence\": {\n",
        "            \"type\": \"Property\",\n",
        "            \"value\": text_sentiment[0]['score']\n",
        "        },\n",
        "        \"isAnalysisOf\": {\n",
        "            \"type\": \"Relationship\",\n",
        "            \"object\": PostId\n",
        "        },\n",
        "        \"@context\": [\n",
        "            \"https://raw.githubusercontent.com/smart-data-models/dataModel.SocialMedia/master/context.jsonld\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return analysis"
      ],
      "metadata": {
        "id": "mQyLtbGq4F7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crawl Tweets and Create the Entities"
      ],
      "metadata": {
        "id": "eaghJ61K4tPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if CreateCollection:\n",
        "  ngsild_collection = CreateCollectionEntity(HashSentence(CollectionDescription), CollectionDescription)\n",
        "\n",
        "# Map each tweet object to a NGSI-LD entity\n",
        "for tweet in tweets:\n",
        "\n",
        "  # SINCE WE HAVE ACCESS TO TWEET TEXT, HERE IS WHERE WE CAN FILTER THE TWEETS AND NOISES!\n",
        "\n",
        "  ngsild_tweet = MapTweet2NGSILD(tweet)\n",
        "  ngsild_user = CreateUserEntity(tweet)\n",
        "\n",
        "  if SentimentAnalysis:\n",
        "    translated_text = GenerateTranslation(tweet['full_text'])\n",
        "    ngsild_sentiment = CreateSentimentAnalysisEntity(tweet, translated_text)\n",
        "\n",
        "    # Save the NGSI-LD entities to a JSON file\n",
        "    with open(f\"{ngsild_sentiment['id']}.json\", \"w\") as f:\n",
        "      f.write(json.dumps(ngsild_sentiment, indent=4))\n",
        "\n",
        "    new_relationship = {\n",
        "        \"type\": \"Relationship\",\n",
        "        \"object\": ngsild_sentiment['id'],\n",
        "        \"datasetId\": \"urn:ngsi-ld:Dataset:SMCollection:0\"}\n",
        "    ngsild_tweet['hasAnalysis'].append(new_relationship)\n",
        "\n",
        "  if BelongsToCollection:\n",
        "    new_relationship = {\n",
        "        \"type\": \"Relationship\",\n",
        "        \"object\": ngsild_tweet['id'],\n",
        "        \"datasetId\":  \"urn:ngsi-ld:Dataset:SMCollection:0\"\n",
        "    }\n",
        "    ngsild_collection['hasPosts'].append(new_relationship)\n",
        "\n",
        "    if SentimentAnalysis:\n",
        "      new_relationship = {\n",
        "        \"type\": \"Relationship\",\n",
        "        \"object\": ngsild_sentiment['id'],\n",
        "        \"datasetId\":  \"urn:ngsi-ld:Dataset:SMCollection:0\"\n",
        "        }\n",
        "      ngsild_collection['hasAnalysis'].append(new_relationship)\n",
        "\n",
        "  # # Save the NGSI-LD entities to a JSON file\n",
        "  with open(f\"{ngsild_tweet['id']}.json\", \"w\") as f:\n",
        "    f.write(json.dumps(ngsild_tweet, indent=4))\n",
        "\n",
        "  with open(f\"{ngsild_user['id']}.json\", \"w\") as f:\n",
        "    f.write(json.dumps(ngsild_user, indent=4))\n",
        "\n",
        "if CreateCollection:\n",
        "  with open(f\"{ngsild_collection['id']}.json\", \"w\") as f:\n",
        "    f.write(json.dumps(ngsild_collection, indent=4))"
      ],
      "metadata": {
        "id": "pV-JZCke4xoX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}